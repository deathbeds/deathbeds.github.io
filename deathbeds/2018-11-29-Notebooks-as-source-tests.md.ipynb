{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook proposes a few requirements for notebooks that are used as source code.  The best practices will:\n",
    "\n",
    "\n",
    "1. Make more readable notebooks.\n",
    "1. Make more reusable notebooks.\n",
    "1. Make more diffable notebooks.\n",
    "2. Make more reproducible notebooks.\n",
    "\n",
    "Tim made a cool project https://github.com/betatim/joli/tree/master/joli and it got me thinking about some tests for notebooks if someone was crazy enough use them as source.  Maybe\n",
    "pytest is a good framework for testing notebooks.  Encouraging testing earlier will improve the longevity of computational thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.input_area {\n",
       "    text-decoration: line-through wavy;    \n",
       "    font-weight: bold;\n",
       "}\n",
       ".input:hover, .nbinput:hover {\n",
       "    text-decoration: none;\n",
       "    font-weight: normal;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    %reload_ext pidgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pytest, IPython, importnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://nbviewer.jupyter.org/github/deathbeds/deathbeds.github.io/blob/master/deathbeds/2018-08-02-better-pytest-reports-with-notebooks.ipynb\n",
    "\n",
    "* https://docs.pytest.org/en/latest/example/nonpython.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    nb  = json.loads(pathlib.Path('2018-11-30-Restart-run-all-precommit.ipynb').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>def monotically_increasing_execution_results(nb):\n",
       "</code></pre>\n",
       "<p><code>monotically_increasing_execution_results</code> tests if the execution count of the code cells in <strong>nb</strong> are monotonically increasing.  This check\n",
       "will assure better different and more reliable state.  This concept is inline with the Million notebook analysis. In that work the execution count\n",
       "is a feature metric for reproducibility.</p>\n",
       "<p><strong>exc</strong> is a list of <code>enumerate</code>d code cells and their <code>\"execution_count\"</code>.</p>\n",
       "<pre><code>    exc = [\n",
       "        (id+1, object['execution_count'])\n",
       "        for id, object in enumerate(\n",
       "            object for object in nb['cells']\n",
       "            if object['cell_type'] == 'code' and object['execution_count'] is not None\n",
       "        ) \n",
       "    ]\n",
       "</code></pre>\n",
       "<p>Strip cells with <code>None</code> for an <code>\"execution_count\"</code>s.</p>\n",
       "<pre><code>    while exc[-1][1] is None: exc.pop()\n",
       "\n",
       "    assert all(itertools.starmap(int.__eq__, exc)), \"\"\"The cells are out of order.\"\"\"\n",
       "</code></pre>"
      ],
      "text/markdown": [
       "    def monotically_increasing_execution_results(nb):\n",
       "`monotically_increasing_execution_results` tests if the execution count of the code cells in __nb__ are monotonically increasing.  This check\n",
       "will assure better different and more reliable state.  This concept is inline with the Million notebook analysis. In that work the execution count\n",
       "is a feature metric for reproducibility.\n",
       "    \n",
       "__exc__ is a list of `enumerate`d code cells and their `\"execution_count\"`.\n",
       "        \n",
       "        exc = [\n",
       "            (id+1, object['execution_count'])\n",
       "            for id, object in enumerate(\n",
       "                object for object in nb['cells']\n",
       "                if object['cell_type'] == 'code' and object['execution_count'] is not None\n",
       "            ) \n",
       "        ]\n",
       "Strip cells with `None` for an `\"execution_count\"`s.\n",
       "\n",
       "        while exc[-1][1] is None: exc.pop()\n",
       "        \n",
       "        assert all(itertools.starmap(int.__eq__, exc)), \"\"\"The cells are out of order.\"\"\""
      ],
      "text/plain": [
       "'    def monotically_increasing_execution_results(nb):\\n`monotically_increasing_execution_results` tests if the execution count of the code cells in __nb__ are monotonically increasing.  This check\\nwill assure better different and more reliable state.  This concept is inline with the Million notebook analysis. In that work the execution count\\nis a feature metric for reproducibility.\\n    \\n__exc__ is a list of `enumerate`d code cells and their `\"execution_count\"`.\\n        \\n        exc = [\\n            (id+1, object[\\'execution_count\\'])\\n            for id, object in enumerate(\\n                object for object in nb[\\'cells\\']\\n                if object[\\'cell_type\\'] == \\'code\\' and object[\\'execution_count\\'] is not None\\n            ) \\n        ]\\nStrip cells with `None` for an `\"execution_count\"`s.\\n\\n        while exc[-1][1] is None: exc.pop()\\n        \\n        assert all(itertools.starmap(int.__eq__, exc)), \"\"\"The cells are out of order.\"\"\"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    def monotically_increasing_execution_results(nb):\n",
    "`monotically_increasing_execution_results` tests if the execution count of the code cells in __nb__ are monotonically increasing.  This check\n",
    "will assure better different and more reliable state.  This concept is inline with the Million notebook analysis. In that work the execution count\n",
    "is a feature metric for reproducibility.\n",
    "    \n",
    "__exc__ is a list of `enumerate`d code cells and their `\"execution_count\"`.\n",
    "        \n",
    "        exc = [\n",
    "            (id+1, object['execution_count'])\n",
    "            for id, object in enumerate(\n",
    "                object for object in nb['cells']\n",
    "                if object['cell_type'] == 'code' and object['execution_count'] is not None\n",
    "            ) \n",
    "        ]\n",
    "Strip cells with `None` for an `\"execution_count\"`s.\n",
    "\n",
    "        while exc[-1][1] is None: exc.pop()\n",
    "        \n",
    "        assert all(itertools.starmap(int.__eq__, exc)), \"\"\"The cells are out of order.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>def has_markdown_docstring(nb):\n",
       "</code></pre>\n",
       "<p><code>has_markdown_docstring</code> ensures the source starts with <strong>Markdown</strong>, and thereby the docstring.  This opinion is a consequent of the <code>importnb</code> library.</p>\n",
       "<pre><code>    assert nb['cells'][0]['cell_type'] == 'markdown', \"\"\"The cell in notebook source code should be a __Markdown__ docstring.\"\"\"\n",
       "</code></pre>"
      ],
      "text/markdown": [
       "    def has_markdown_docstring(nb):\n",
       "`has_markdown_docstring` ensures the source starts with __Markdown__, and thereby the docstring.  This opinion is a consequent of the `importnb` library.\n",
       "    \n",
       "        assert nb['cells'][0]['cell_type'] == 'markdown', \"\"\"The cell in notebook source code should be a __Markdown__ docstring.\"\"\""
      ],
      "text/plain": [
       "'    def has_markdown_docstring(nb):\\n`has_markdown_docstring` ensures the source starts with __Markdown__, and thereby the docstring.  This opinion is a consequent of the `importnb` library.\\n    \\n        assert nb[\\'cells\\'][0][\\'cell_type\\'] == \\'markdown\\', \"\"\"The cell in notebook source code should be a __Markdown__ docstring.\"\"\"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    def has_markdown_docstring(nb):\n",
    "`has_markdown_docstring` ensures the source starts with __Markdown__, and thereby the docstring.  This opinion is a consequent of the `importnb` library.\n",
    "    \n",
    "        assert nb['cells'][0]['cell_type'] == 'markdown', \"\"\"The cell in notebook source code should be a __Markdown__ docstring.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # content of conftest.py\n",
    "    import pytest, pidgin, pathlib, json, itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>def pytest_collect_file(parent, path):\n",
       "</code></pre>\n",
       "<p><code>pytest_collect_file</code> will collect notebooks.</p>\n",
       "<pre><code>    if path.ext == \".ipynb\": return NotebookFile(path, parent)\n",
       "</code></pre>"
      ],
      "text/markdown": [
       "    def pytest_collect_file(parent, path):\n",
       "`pytest_collect_file` will collect notebooks.\n",
       "\n",
       "        if path.ext == \".ipynb\": return NotebookFile(path, parent)"
      ],
      "text/plain": [
       "'    def pytest_collect_file(parent, path):\\n`pytest_collect_file` will collect notebooks.\\n\\n        if path.ext == \".ipynb\": return NotebookFile(path, parent)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    def pytest_collect_file(parent, path):\n",
    "`pytest_collect_file` will collect notebooks.\n",
    "\n",
    "        if path.ext == \".ipynb\": return NotebookFile(path, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>class NotebookFile(pytest.File):\n",
       "    def collect(self):\n",
       "</code></pre>\n",
       "<p><code>NotebookFile.collect</code> reads the notebook and runs just one test for now.</p>\n",
       "<pre><code>        nb = __import__('json').load(self.fspath.open())\n",
       "        yield from(\n",
       "            AggregateNotebookTests(callable.__name__, self, nb, callable) for callable in (\n",
       "                monotically_increasing_execution_results, \n",
       "                has_markdown_docstring\n",
       "            )\n",
       "        )\n",
       "</code></pre>"
      ],
      "text/markdown": [
       "    class NotebookFile(pytest.File):\n",
       "        def collect(self):\n",
       "`NotebookFile.collect` reads the notebook and runs just one test for now.\n",
       "            \n",
       "            nb = __import__('json').load(self.fspath.open())\n",
       "            yield from(\n",
       "                AggregateNotebookTests(callable.__name__, self, nb, callable) for callable in (\n",
       "                    monotically_increasing_execution_results, \n",
       "                    has_markdown_docstring\n",
       "                )\n",
       "            )"
      ],
      "text/plain": [
       "\"    class NotebookFile(pytest.File):\\n        def collect(self):\\n`NotebookFile.collect` reads the notebook and runs just one test for now.\\n            \\n            nb = __import__('json').load(self.fspath.open())\\n            yield from(\\n                AggregateNotebookTests(callable.__name__, self, nb, callable) for callable in (\\n                    monotically_increasing_execution_results, \\n                    has_markdown_docstring\\n                )\\n            )\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    class NotebookFile(pytest.File):\n",
    "        def collect(self):\n",
    "`NotebookFile.collect` reads the notebook and runs just one test for now.\n",
    "            \n",
    "            nb = __import__('json').load(self.fspath.open())\n",
    "            yield from(\n",
    "                AggregateNotebookTests(callable.__name__, self, nb, callable) for callable in (\n",
    "                    monotically_increasing_execution_results, \n",
    "                    has_markdown_docstring\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>class AggregateNotebookTests(pytest.Item):\n",
       "</code></pre>\n",
       "<p><code>AggregateNotebookTests</code> is a <code>pytest.Item</code> for testing features of notebook data.</p>\n",
       "<pre><code>    def runtest(self):  return self.callable(self.nb)\n",
       "\n",
       "    def __init__(self, name, parent, nb, callable):\n",
       "        super().__init__(name, parent)\n",
       "        self.nb, self.callable = nb, callable\n",
       "</code></pre>\n",
       "<p><code>AggregateNotebookTests.repr_failure</code> is really similar the to the <b><i>render_traceback</i></b> attribute provided by <code>IPython</code> to customize tracebacks.</p>\n",
       "<pre><code>    def reportinfo(self): return self.fspath, 0, \"usecase: %s\" % self.name\n",
       "</code></pre>"
      ],
      "text/markdown": [
       "    class AggregateNotebookTests(pytest.Item):\n",
       "`AggregateNotebookTests` is a `pytest.Item` for testing features of notebook data.\n",
       "\n",
       "        def runtest(self):  return self.callable(self.nb)\n",
       "        \n",
       "        def __init__(self, name, parent, nb, callable):\n",
       "            super().__init__(name, parent)\n",
       "            self.nb, self.callable = nb, callable\n",
       "\n",
       "`AggregateNotebookTests.repr_failure` is really similar the to the <b><i>render_traceback</i></b> attribute provided by `IPython` to customize tracebacks.\n",
       "\n",
       "        \n",
       "        def reportinfo(self): return self.fspath, 0, \"usecase: %s\" % self.name\n"
      ],
      "text/plain": [
       "'    class AggregateNotebookTests(pytest.Item):\\n`AggregateNotebookTests` is a `pytest.Item` for testing features of notebook data.\\n\\n        def runtest(self):  return self.callable(self.nb)\\n        \\n        def __init__(self, name, parent, nb, callable):\\n            super().__init__(name, parent)\\n            self.nb, self.callable = nb, callable\\n\\n`AggregateNotebookTests.repr_failure` is really similar the to the <b><i>render_traceback</i></b> attribute provided by `IPython` to customize tracebacks.\\n\\n        \\n        def reportinfo(self): return self.fspath, 0, \"usecase: %s\" % self.name\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    class AggregateNotebookTests(pytest.Item):\n",
    "`AggregateNotebookTests` is a `pytest.Item` for testing features of notebook data.\n",
    "\n",
    "        def runtest(self):  return self.callable(self.nb)\n",
    "        \n",
    "        def __init__(self, name, parent, nb, callable):\n",
    "            super().__init__(name, parent)\n",
    "            self.nb, self.callable = nb, callable\n",
    "\n",
    "`AggregateNotebookTests.repr_failure` is really similar the to the <b><i>render_traceback</i></b> attribute provided by `IPython` to customize tracebacks.\n",
    "\n",
    "        \n",
    "        def reportinfo(self): return self.fspath, 0, \"usecase: %s\" % self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.6.6, pytest-3.5.1, py-1.5.3, pluggy-0.6.0\n",
      "rootdir: C:\\Users\\deathbeds\\deathbeds.github.io, inifile:\n",
      "plugins: xonsh-0.8.1, doctestplus-0.1.3, cov-2.6.0, nbval-0.9.1, hypothesis-3.66.16, pidgin-0.3.0, importnb-0.5.1\n",
      "collected 12 items\n",
      "\n",
      "2018-11-29-Notebooks-as-source-tests.md.ipynb .....FFF....               [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "_______ deathbeds\\2018-11-29-Notebooks-as-source-tests.md.ipynb::Cell 5 _______\n",
      "\u001b[91mNotebook cell execution failed\u001b[0m\n",
      "\u001b[94mCell 5: Unrun reference cell has outputs\n",
      "\n",
      "Input:\n",
      "\u001b[0m    def pytest_collect_file(parent, path):\n",
      "`pytest_collect_file` will collect notebooks.\n",
      "\n",
      "        if path.ext == \".ipynb\": return NotebookFile(path, parent)\n",
      "\n",
      "_______ deathbeds\\2018-11-29-Notebooks-as-source-tests.md.ipynb::Cell 6 _______\n",
      "\u001b[91mNotebook cell execution failed\u001b[0m\n",
      "\u001b[94mCell 6: Unrun reference cell has outputs\n",
      "\n",
      "Input:\n",
      "\u001b[0m    class NotebookFile(pytest.File):\n",
      "        def collect(self):\n",
      "`NotebookFile.collect` reads the notebook and runs just one test for now.\n",
      "            \n",
      "            nb = __import__('json').load(self.fspath.open())\n",
      "            yield from(\n",
      "                AggregateNotebookTests(callable.__name__, self, nb, callable) for callable in (\n",
      "                    monotically_increasing_execution_results, \n",
      "                    has_markdown_docstring\n",
      "                )\n",
      "            )\n",
      "\n",
      "_______ deathbeds\\2018-11-29-Notebooks-as-source-tests.md.ipynb::Cell 7 _______\n",
      "\u001b[91mNotebook cell execution failed\u001b[0m\n",
      "\u001b[94mCell 7: Unrun reference cell has outputs\n",
      "\n",
      "Input:\n",
      "\u001b[0m    class AggregateNotebookTests(pytest.Item):\n",
      "`AggregateNotebookTests` is a `pytest.Item` for testing features of notebook data.\n",
      "\n",
      "        def runtest(self):  return self.callable(self.nb)\n",
      "        \n",
      "        def __init__(self, name, parent, nb, callable):\n",
      "            super().__init__(name, parent)\n",
      "            self.nb, self.callable = nb, callable\n",
      "\n",
      "`AggregateNotebookTests.repr_failure` is really similar the to the <b><i>render_traceback</i></b> attribute provided by `IPython` to customize tracebacks.\n",
      "\n",
      "        \n",
      "        def reportinfo(self): return self.fspath, 0, \"usecase: %s\" % self.name\n",
      "\n",
      "\n",
      "===================== 3 failed, 9 passed in 6.62 seconds ======================\n"
     ]
    }
   ],
   "source": [
    "    def _run_pytest_example(): \n",
    "        pytest.main('--nbval 2018-11-29-Notebooks-as-source-tests.md.ipynb'.split(), [__import__(__name__)])\n",
    "        \n",
    "    \n",
    "    if __name__ == '__main__' and not __import__('os').environ.get('PYTEST_CURRENT_TEST', None):\n",
    "        with IPython.utils.capture.capture_output() as report:\n",
    "            _run_pytest_example()\n",
    "        print('\\n'.join(report.stdout.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
