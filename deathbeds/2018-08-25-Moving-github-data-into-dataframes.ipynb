{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading issues and pull requests.\n",
    "\n",
    "This document provides a basis for researching Github data locally.  It uses the a repository's metadata to access the Github Issues and Pull Requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pandas; import requests; from functools import partial\n",
    "    from requests_cache import install_cache\n",
    "    install_cache('github-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "    info = lambda x, **params: pandas.Series(requests.get(\"https://api.github.com/repos/{}\".format(x), params=params).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "    events = lambda action, x, **params: pandas.DataFrame(requests.get(\n",
    "        info(x, **params).loc[f'{action}_url'].format(**{'/number': ''})).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def pulls(\n",
    "        project: str, \n",
    "        iter: int=2, \n",
    "        state: ('open', 'closed', 'all')='closed'\n",
    "    ) -> iter:\n",
    "        \"\"\"Download the pull requests over {iter} pages for specific state of\n",
    "        pull request\"\"\"\n",
    "        for i in range(1, iter):\n",
    "            result = events(project, 'pulls', state=state, page=i)\n",
    "            yield result\n",
    "            if len(result) < 30: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_jupyterlab(): \n",
    "        assert len(pandas.concat(list(pulls('jupyterlab/jupyterlab'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.6.5, pytest-3.5.1, py-1.5.3, pluggy-0.6.0\n",
      "Matplotlib: 2.2.2\n",
      "Freetype: 2.8.1\n",
      "rootdir: C:\\Users\\deathbeds, inifile:\n",
      "plugins: xdist-1.22.5, testmon-0.9.12, remotedata-0.2.1, parallel-0.0.2, openfiles-0.3.0, mpl-0.9, localserver-0.4.1, forked-0.2, doctestplus-0.1.3, arraydiff-0.2, hypothesis-3.66.16, importnb-0.5.0\n",
      "collected 1 item\n",
      "\n",
      "pulls.ipynb F                                                            [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "_______________________________ test_jupyterlab _______________________________\n",
      "\n",
      "self = <urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>\n",
      "\n",
      "    def _new_conn(self):\n",
      "        \"\"\" Establish a socket connection and set nodelay settings on it.\n",
      "    \n",
      "            :return: New socket connection.\n",
      "            \"\"\"\n",
      "        extra_kw = {}\n",
      "        if self.source_address:\n",
      "            extra_kw['source_address'] = self.source_address\n",
      "    \n",
      "        if self.socket_options:\n",
      "            extra_kw['socket_options'] = self.socket_options\n",
      "    \n",
      "        try:\n",
      "            conn = connection.create_connection(\n",
      ">               (self.host, self.port), self.timeout, **extra_kw)\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py:141: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "address = ('api.github.com', 443), timeout = None, source_address = None\n",
      "socket_options = [(6, 1, 1)]\n",
      "\n",
      "    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n",
      "                          source_address=None, socket_options=None):\n",
      "        \"\"\"Connect to *address* and return the socket object.\n",
      "    \n",
      "        Convenience function.  Connect to *address* (a 2-tuple ``(host,\n",
      "        port)``) and return the socket object.  Passing the optional\n",
      "        *timeout* parameter will set the timeout on the socket instance\n",
      "        before attempting to connect.  If no *timeout* is supplied, the\n",
      "        global default timeout setting returned by :func:`getdefaulttimeout`\n",
      "        is used.  If *source_address* is set it must be a tuple of (host, port)\n",
      "        for the socket to bind as a source address before making the connection.\n",
      "        An host of '' or port 0 tells the OS to use the default.\n",
      "        \"\"\"\n",
      "    \n",
      "        host, port = address\n",
      "        if host.startswith('['):\n",
      "            host = host.strip('[]')\n",
      "        err = None\n",
      "    \n",
      "        # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n",
      "        # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n",
      "        # The original create_connection function always returns all records.\n",
      "        family = allowed_gai_family()\n",
      "    \n",
      ">       for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:60: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "host = 'api.github.com', port = 443, family = <AddressFamily.AF_UNSPEC: 0>\n",
      "type = <SocketKind.SOCK_STREAM: 1>, proto = 0, flags = 0\n",
      "\n",
      "    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n",
      "        \"\"\"Resolve host and port into list of address info entries.\n",
      "    \n",
      "        Translate the host/port argument into a sequence of 5-tuples that contain\n",
      "        all the necessary arguments for creating a socket connected to that service.\n",
      "        host is a domain name, a string representation of an IPv4/v6 address or\n",
      "        None. port is a string service name such as 'http', a numeric port number or\n",
      "        None. By passing None as the value of host and port, you can pass NULL to\n",
      "        the underlying C API.\n",
      "    \n",
      "        The family, type and proto arguments can be optionally specified in order to\n",
      "        narrow the list of addresses returned. Passing zero as a value for each of\n",
      "        these arguments selects the full range of results.\n",
      "        \"\"\"\n",
      "        # We override this function since we want to translate the numeric family\n",
      "        # and socket type values to enum constants.\n",
      "        addrlist = []\n",
      ">       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "E       socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "C:\\Anaconda3\\lib\\socket.py:745: gaierror\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x00000264B41DA1D0>\n",
      "method = 'GET', url = '/repos/pulls?page=1&state=closed', body = None\n",
      "headers = {'User-Agent': 'python-requests/2.18.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n",
      "retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n",
      "redirect = False, assert_same_host = False\n",
      "timeout = <urllib3.util.timeout.Timeout object at 0x00000264B41DA208>\n",
      "pool_timeout = None, release_conn = False, chunked = False, body_pos = None\n",
      "response_kw = {'decode_content': False, 'preload_content': False}, conn = None\n",
      "release_this_conn = True, err = None, clean_exit = False\n",
      "timeout_obj = <urllib3.util.timeout.Timeout object at 0x00000264B3D49FD0>\n",
      "is_new_proxy_conn = False\n",
      "\n",
      "    def urlopen(self, method, url, body=None, headers=None, retries=None,\n",
      "                redirect=True, assert_same_host=True, timeout=_Default,\n",
      "                pool_timeout=None, release_conn=None, chunked=False,\n",
      "                body_pos=None, **response_kw):\n",
      "        \"\"\"\n",
      "            Get a connection from the pool and perform an HTTP request. This is the\n",
      "            lowest level call for making a request, so you'll need to specify all\n",
      "            the raw details.\n",
      "    \n",
      "            .. note::\n",
      "    \n",
      "               More commonly, it's appropriate to use a convenience method provided\n",
      "               by :class:`.RequestMethods`, such as :meth:`request`.\n",
      "    \n",
      "            .. note::\n",
      "    \n",
      "               `release_conn` will only behave as expected if\n",
      "               `preload_content=False` because we want to make\n",
      "               `preload_content=False` the default behaviour someday soon without\n",
      "               breaking backwards compatibility.\n",
      "    \n",
      "            :param method:\n",
      "                HTTP request method (such as GET, POST, PUT, etc.)\n",
      "    \n",
      "            :param body:\n",
      "                Data to send in the request body (useful for creating\n",
      "                POST requests, see HTTPConnectionPool.post_url for\n",
      "                more convenience).\n",
      "    \n",
      "            :param headers:\n",
      "                Dictionary of custom headers to send, such as User-Agent,\n",
      "                If-None-Match, etc. If None, pool headers are used. If provided,\n",
      "                these headers completely replace any pool-specific headers.\n",
      "    \n",
      "            :param retries:\n",
      "                Configure the number of retries to allow before raising a\n",
      "                :class:`~urllib3.exceptions.MaxRetryError` exception.\n",
      "    \n",
      "                Pass ``None`` to retry until you receive a response. Pass a\n",
      "                :class:`~urllib3.util.retry.Retry` object for fine-grained control\n",
      "                over different types of retries.\n",
      "                Pass an integer number to retry connection errors that many times,\n",
      "                but no other types of errors. Pass zero to never retry.\n",
      "    \n",
      "                If ``False``, then retries are disabled and any exception is raised\n",
      "                immediately. Also, instead of raising a MaxRetryError on redirects,\n",
      "                the redirect response will be returned.\n",
      "    \n",
      "            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n",
      "    \n",
      "            :param redirect:\n",
      "                If True, automatically handle redirects (status codes 301, 302,\n",
      "                303, 307, 308). Each redirect counts as a retry. Disabling retries\n",
      "                will disable redirect, too.\n",
      "    \n",
      "            :param assert_same_host:\n",
      "                If ``True``, will make sure that the host of the pool requests is\n",
      "                consistent else will raise HostChangedError. When False, you can\n",
      "                use the pool on an HTTP proxy and request foreign hosts.\n",
      "    \n",
      "            :param timeout:\n",
      "                If specified, overrides the default timeout for this one\n",
      "                request. It may be a float (in seconds) or an instance of\n",
      "                :class:`urllib3.util.Timeout`.\n",
      "    \n",
      "            :param pool_timeout:\n",
      "                If set and the pool is set to block=True, then this method will\n",
      "                block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n",
      "                connection is available within the time period.\n",
      "    \n",
      "            :param release_conn:\n",
      "                If False, then the urlopen call will not release the connection\n",
      "                back into the pool once a response is received (but will release if\n",
      "                you read the entire contents of the response such as when\n",
      "                `preload_content=True`). This is useful if you're not preloading\n",
      "                the response's content immediately. You will need to call\n",
      "                ``r.release_conn()`` on the response ``r`` to return the connection\n",
      "                back into the pool. If None, it takes the value of\n",
      "                ``response_kw.get('preload_content', True)``.\n",
      "    \n",
      "            :param chunked:\n",
      "                If True, urllib3 will send the body using chunked transfer\n",
      "                encoding. Otherwise, urllib3 will send the body using the standard\n",
      "                content-length form. Defaults to False.\n",
      "    \n",
      "            :param int body_pos:\n",
      "                Position to seek to in file-like body in the event of a retry or\n",
      "                redirect. Typically this won't need to be set because urllib3 will\n",
      "                auto-populate the value when needed.\n",
      "    \n",
      "            :param \\\\**response_kw:\n",
      "                Additional parameters are passed to\n",
      "                :meth:`urllib3.response.HTTPResponse.from_httplib`\n",
      "            \"\"\"\n",
      "        if headers is None:\n",
      "            headers = self.headers\n",
      "    \n",
      "        if not isinstance(retries, Retry):\n",
      "            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n",
      "    \n",
      "        if release_conn is None:\n",
      "            release_conn = response_kw.get('preload_content', True)\n",
      "    \n",
      "        # Check host\n",
      "        if assert_same_host and not self.is_same_host(url):\n",
      "            raise HostChangedError(self, url, retries)\n",
      "    \n",
      "        conn = None\n",
      "    \n",
      "        # Track whether `conn` needs to be released before\n",
      "        # returning/raising/recursing. Update this variable if necessary, and\n",
      "        # leave `release_conn` constant throughout the function. That way, if\n",
      "        # the function recurses, the original value of `release_conn` will be\n",
      "        # passed down into the recursive call, and its value will be respected.\n",
      "        #\n",
      "        # See issue #651 [1] for details.\n",
      "        #\n",
      "        # [1] <https://github.com/shazow/urllib3/issues/651>\n",
      "        release_this_conn = release_conn\n",
      "    \n",
      "        # Merge the proxy headers. Only do this in HTTP. We have to copy the\n",
      "        # headers dict so we can safely change it without those changes being\n",
      "        # reflected in anyone else's copy.\n",
      "        if self.scheme == 'http':\n",
      "            headers = headers.copy()\n",
      "            headers.update(self.proxy_headers)\n",
      "    \n",
      "        # Must keep the exception bound to a separate variable or else Python 3\n",
      "        # complains about UnboundLocalError.\n",
      "        err = None\n",
      "    \n",
      "        # Keep track of whether we cleanly exited the except block. This\n",
      "        # ensures we do proper cleanup in finally.\n",
      "        clean_exit = False\n",
      "    \n",
      "        # Rewind body position, if needed. Record current position\n",
      "        # for future rewinds in the event of a redirect/retry.\n",
      "        body_pos = set_file_position(body, body_pos)\n",
      "    \n",
      "        try:\n",
      "            # Request a connection from the queue.\n",
      "            timeout_obj = self._get_timeout(timeout)\n",
      "            conn = self._get_conn(timeout=pool_timeout)\n",
      "    \n",
      "            conn.timeout = timeout_obj.connect_timeout\n",
      "    \n",
      "            is_new_proxy_conn = self.proxy is not None and not getattr(conn, 'sock', None)\n",
      "            if is_new_proxy_conn:\n",
      "                self._prepare_proxy(conn)\n",
      "    \n",
      "            # Make the request on the httplib connection object.\n",
      "            httplib_response = self._make_request(conn, method, url,\n",
      "                                                  timeout=timeout_obj,\n",
      "                                                  body=body, headers=headers,\n",
      ">                                                 chunked=chunked)\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:601: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x00000264B41DA1D0>\n",
      "conn = <urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>\n",
      "method = 'GET', url = '/repos/pulls?page=1&state=closed'\n",
      "timeout = <urllib3.util.timeout.Timeout object at 0x00000264B3D49FD0>\n",
      "chunked = False\n",
      "httplib_request_kw = {'body': None, 'headers': {'User-Agent': 'python-requests/2.18.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}}\n",
      "timeout_obj = <urllib3.util.timeout.Timeout object at 0x00000264B34C9D68>\n",
      "\n",
      "    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,\n",
      "                      **httplib_request_kw):\n",
      "        \"\"\"\n",
      "            Perform a request on a given urllib connection object taken from our\n",
      "            pool.\n",
      "    \n",
      "            :param conn:\n",
      "                a connection from one of our connection pools\n",
      "    \n",
      "            :param timeout:\n",
      "                Socket timeout in seconds for the request. This can be a\n",
      "                float or integer, which will set the same timeout value for\n",
      "                the socket connect and the socket read, or an instance of\n",
      "                :class:`urllib3.util.Timeout`, which gives you more fine-grained\n",
      "                control over your timeouts.\n",
      "            \"\"\"\n",
      "        self.num_requests += 1\n",
      "    \n",
      "        timeout_obj = self._get_timeout(timeout)\n",
      "        timeout_obj.start_connect()\n",
      "        conn.timeout = timeout_obj.connect_timeout\n",
      "    \n",
      "        # Trigger any extra validation we need to do.\n",
      "        try:\n",
      ">           self._validate_conn(conn)\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:346: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x00000264B41DA1D0>\n",
      "conn = <urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>\n",
      "\n",
      "    def _validate_conn(self, conn):\n",
      "        \"\"\"\n",
      "            Called right before a request is made, after the socket is created.\n",
      "            \"\"\"\n",
      "        super(HTTPSConnectionPool, self)._validate_conn(conn)\n",
      "    \n",
      "        # Force connect early to allow us to validate the connection.\n",
      "        if not getattr(conn, 'sock', None):  # AppEngine might not have  `.sock`\n",
      ">           conn.connect()\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:850: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>\n",
      "\n",
      "    def connect(self):\n",
      "        # Add certificate verification\n",
      ">       conn = self._new_conn()\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py:284: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>\n",
      "\n",
      "    def _new_conn(self):\n",
      "        \"\"\" Establish a socket connection and set nodelay settings on it.\n",
      "    \n",
      "            :return: New socket connection.\n",
      "            \"\"\"\n",
      "        extra_kw = {}\n",
      "        if self.source_address:\n",
      "            extra_kw['source_address'] = self.source_address\n",
      "    \n",
      "        if self.socket_options:\n",
      "            extra_kw['socket_options'] = self.socket_options\n",
      "    \n",
      "        try:\n",
      "            conn = connection.create_connection(\n",
      "                (self.host, self.port), self.timeout, **extra_kw)\n",
      "    \n",
      "        except SocketTimeout as e:\n",
      "            raise ConnectTimeoutError(\n",
      "                self, \"Connection to %s timed out. (connect timeout=%s)\" %\n",
      "                (self.host, self.timeout))\n",
      "    \n",
      "        except SocketError as e:\n",
      "            raise NewConnectionError(\n",
      ">               self, \"Failed to establish a new connection: %s\" % e)\n",
      "E           urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py:150: NewConnectionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "self = <requests.adapters.HTTPAdapter object at 0x00000264B41FAFD0>\n",
      "request = <PreparedRequest [GET]>, stream = False\n",
      "timeout = <urllib3.util.timeout.Timeout object at 0x00000264B41DA208>\n",
      "verify = True, cert = None, proxies = OrderedDict()\n",
      "\n",
      "    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n",
      "        \"\"\"Sends PreparedRequest object. Returns Response object.\n",
      "    \n",
      "            :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n",
      "            :param stream: (optional) Whether to stream the request content.\n",
      "            :param timeout: (optional) How long to wait for the server to send\n",
      "                data before giving up, as a float, or a :ref:`(connect timeout,\n",
      "                read timeout) <timeouts>` tuple.\n",
      "            :type timeout: float or tuple or urllib3 Timeout object\n",
      "            :param verify: (optional) Either a boolean, in which case it controls whether\n",
      "                we verify the server's TLS certificate, or a string, in which case it\n",
      "                must be a path to a CA bundle to use\n",
      "            :param cert: (optional) Any user-provided SSL certificate to be trusted.\n",
      "            :param proxies: (optional) The proxies dictionary to apply to the request.\n",
      "            :rtype: requests.Response\n",
      "            \"\"\"\n",
      "    \n",
      "        conn = self.get_connection(request.url, proxies)\n",
      "    \n",
      "        self.cert_verify(conn, request.url, verify, cert)\n",
      "        url = self.request_url(request, proxies)\n",
      "        self.add_headers(request)\n",
      "    \n",
      "        chunked = not (request.body is None or 'Content-Length' in request.headers)\n",
      "    \n",
      "        if isinstance(timeout, tuple):\n",
      "            try:\n",
      "                connect, read = timeout\n",
      "                timeout = TimeoutSauce(connect=connect, read=read)\n",
      "            except ValueError as e:\n",
      "                # this may raise a string formatting error.\n",
      "                err = (\"Invalid timeout {0}. Pass a (connect, read) \"\n",
      "                       \"timeout tuple, or a single float to set \"\n",
      "                       \"both timeouts to the same value\".format(timeout))\n",
      "                raise ValueError(err)\n",
      "        elif isinstance(timeout, TimeoutSauce):\n",
      "            pass\n",
      "        else:\n",
      "            timeout = TimeoutSauce(connect=timeout, read=timeout)\n",
      "    \n",
      "        try:\n",
      "            if not chunked:\n",
      "                resp = conn.urlopen(\n",
      "                    method=request.method,\n",
      "                    url=url,\n",
      "                    body=request.body,\n",
      "                    headers=request.headers,\n",
      "                    redirect=False,\n",
      "                    assert_same_host=False,\n",
      "                    preload_content=False,\n",
      "                    decode_content=False,\n",
      "                    retries=self.max_retries,\n",
      ">                   timeout=timeout\n",
      "                )\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:440: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x00000264B41DA1D0>\n",
      "method = 'GET', url = '/repos/pulls?page=1&state=closed', body = None\n",
      "headers = {'User-Agent': 'python-requests/2.18.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n",
      "retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n",
      "redirect = False, assert_same_host = False\n",
      "timeout = <urllib3.util.timeout.Timeout object at 0x00000264B41DA208>\n",
      "pool_timeout = None, release_conn = False, chunked = False, body_pos = None\n",
      "response_kw = {'decode_content': False, 'preload_content': False}, conn = None\n",
      "release_this_conn = True, err = None, clean_exit = False\n",
      "timeout_obj = <urllib3.util.timeout.Timeout object at 0x00000264B3D49FD0>\n",
      "is_new_proxy_conn = False\n",
      "\n",
      "    def urlopen(self, method, url, body=None, headers=None, retries=None,\n",
      "                redirect=True, assert_same_host=True, timeout=_Default,\n",
      "                pool_timeout=None, release_conn=None, chunked=False,\n",
      "                body_pos=None, **response_kw):\n",
      "        \"\"\"\n",
      "            Get a connection from the pool and perform an HTTP request. This is the\n",
      "            lowest level call for making a request, so you'll need to specify all\n",
      "            the raw details.\n",
      "    \n",
      "            .. note::\n",
      "    \n",
      "               More commonly, it's appropriate to use a convenience method provided\n",
      "               by :class:`.RequestMethods`, such as :meth:`request`.\n",
      "    \n",
      "            .. note::\n",
      "    \n",
      "               `release_conn` will only behave as expected if\n",
      "               `preload_content=False` because we want to make\n",
      "               `preload_content=False` the default behaviour someday soon without\n",
      "               breaking backwards compatibility.\n",
      "    \n",
      "            :param method:\n",
      "                HTTP request method (such as GET, POST, PUT, etc.)\n",
      "    \n",
      "            :param body:\n",
      "                Data to send in the request body (useful for creating\n",
      "                POST requests, see HTTPConnectionPool.post_url for\n",
      "                more convenience).\n",
      "    \n",
      "            :param headers:\n",
      "                Dictionary of custom headers to send, such as User-Agent,\n",
      "                If-None-Match, etc. If None, pool headers are used. If provided,\n",
      "                these headers completely replace any pool-specific headers.\n",
      "    \n",
      "            :param retries:\n",
      "                Configure the number of retries to allow before raising a\n",
      "                :class:`~urllib3.exceptions.MaxRetryError` exception.\n",
      "    \n",
      "                Pass ``None`` to retry until you receive a response. Pass a\n",
      "                :class:`~urllib3.util.retry.Retry` object for fine-grained control\n",
      "                over different types of retries.\n",
      "                Pass an integer number to retry connection errors that many times,\n",
      "                but no other types of errors. Pass zero to never retry.\n",
      "    \n",
      "                If ``False``, then retries are disabled and any exception is raised\n",
      "                immediately. Also, instead of raising a MaxRetryError on redirects,\n",
      "                the redirect response will be returned.\n",
      "    \n",
      "            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n",
      "    \n",
      "            :param redirect:\n",
      "                If True, automatically handle redirects (status codes 301, 302,\n",
      "                303, 307, 308). Each redirect counts as a retry. Disabling retries\n",
      "                will disable redirect, too.\n",
      "    \n",
      "            :param assert_same_host:\n",
      "                If ``True``, will make sure that the host of the pool requests is\n",
      "                consistent else will raise HostChangedError. When False, you can\n",
      "                use the pool on an HTTP proxy and request foreign hosts.\n",
      "    \n",
      "            :param timeout:\n",
      "                If specified, overrides the default timeout for this one\n",
      "                request. It may be a float (in seconds) or an instance of\n",
      "                :class:`urllib3.util.Timeout`.\n",
      "    \n",
      "            :param pool_timeout:\n",
      "                If set and the pool is set to block=True, then this method will\n",
      "                block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n",
      "                connection is available within the time period.\n",
      "    \n",
      "            :param release_conn:\n",
      "                If False, then the urlopen call will not release the connection\n",
      "                back into the pool once a response is received (but will release if\n",
      "                you read the entire contents of the response such as when\n",
      "                `preload_content=True`). This is useful if you're not preloading\n",
      "                the response's content immediately. You will need to call\n",
      "                ``r.release_conn()`` on the response ``r`` to return the connection\n",
      "                back into the pool. If None, it takes the value of\n",
      "                ``response_kw.get('preload_content', True)``.\n",
      "    \n",
      "            :param chunked:\n",
      "                If True, urllib3 will send the body using chunked transfer\n",
      "                encoding. Otherwise, urllib3 will send the body using the standard\n",
      "                content-length form. Defaults to False.\n",
      "    \n",
      "            :param int body_pos:\n",
      "                Position to seek to in file-like body in the event of a retry or\n",
      "                redirect. Typically this won't need to be set because urllib3 will\n",
      "                auto-populate the value when needed.\n",
      "    \n",
      "            :param \\\\**response_kw:\n",
      "                Additional parameters are passed to\n",
      "                :meth:`urllib3.response.HTTPResponse.from_httplib`\n",
      "            \"\"\"\n",
      "        if headers is None:\n",
      "            headers = self.headers\n",
      "    \n",
      "        if not isinstance(retries, Retry):\n",
      "            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n",
      "    \n",
      "        if release_conn is None:\n",
      "            release_conn = response_kw.get('preload_content', True)\n",
      "    \n",
      "        # Check host\n",
      "        if assert_same_host and not self.is_same_host(url):\n",
      "            raise HostChangedError(self, url, retries)\n",
      "    \n",
      "        conn = None\n",
      "    \n",
      "        # Track whether `conn` needs to be released before\n",
      "        # returning/raising/recursing. Update this variable if necessary, and\n",
      "        # leave `release_conn` constant throughout the function. That way, if\n",
      "        # the function recurses, the original value of `release_conn` will be\n",
      "        # passed down into the recursive call, and its value will be respected.\n",
      "        #\n",
      "        # See issue #651 [1] for details.\n",
      "        #\n",
      "        # [1] <https://github.com/shazow/urllib3/issues/651>\n",
      "        release_this_conn = release_conn\n",
      "    \n",
      "        # Merge the proxy headers. Only do this in HTTP. We have to copy the\n",
      "        # headers dict so we can safely change it without those changes being\n",
      "        # reflected in anyone else's copy.\n",
      "        if self.scheme == 'http':\n",
      "            headers = headers.copy()\n",
      "            headers.update(self.proxy_headers)\n",
      "    \n",
      "        # Must keep the exception bound to a separate variable or else Python 3\n",
      "        # complains about UnboundLocalError.\n",
      "        err = None\n",
      "    \n",
      "        # Keep track of whether we cleanly exited the except block. This\n",
      "        # ensures we do proper cleanup in finally.\n",
      "        clean_exit = False\n",
      "    \n",
      "        # Rewind body position, if needed. Record current position\n",
      "        # for future rewinds in the event of a redirect/retry.\n",
      "        body_pos = set_file_position(body, body_pos)\n",
      "    \n",
      "        try:\n",
      "            # Request a connection from the queue.\n",
      "            timeout_obj = self._get_timeout(timeout)\n",
      "            conn = self._get_conn(timeout=pool_timeout)\n",
      "    \n",
      "            conn.timeout = timeout_obj.connect_timeout\n",
      "    \n",
      "            is_new_proxy_conn = self.proxy is not None and not getattr(conn, 'sock', None)\n",
      "            if is_new_proxy_conn:\n",
      "                self._prepare_proxy(conn)\n",
      "    \n",
      "            # Make the request on the httplib connection object.\n",
      "            httplib_response = self._make_request(conn, method, url,\n",
      "                                                  timeout=timeout_obj,\n",
      "                                                  body=body, headers=headers,\n",
      "                                                  chunked=chunked)\n",
      "    \n",
      "            # If we're going to release the connection in ``finally:``, then\n",
      "            # the response doesn't need to know about the connection. Otherwise\n",
      "            # it will also try to release it and we'll have a double-release\n",
      "            # mess.\n",
      "            response_conn = conn if not release_conn else None\n",
      "    \n",
      "            # Pass method to Response for length checking\n",
      "            response_kw['request_method'] = method\n",
      "    \n",
      "            # Import httplib's response into our own wrapper object\n",
      "            response = self.ResponseCls.from_httplib(httplib_response,\n",
      "                                                     pool=self,\n",
      "                                                     connection=response_conn,\n",
      "                                                     retries=retries,\n",
      "                                                     **response_kw)\n",
      "    \n",
      "            # Everything went great!\n",
      "            clean_exit = True\n",
      "    \n",
      "        except queue.Empty:\n",
      "            # Timed out by queue.\n",
      "            raise EmptyPoolError(self, \"No pool connections are available.\")\n",
      "    \n",
      "        except (TimeoutError, HTTPException, SocketError, ProtocolError,\n",
      "                BaseSSLError, SSLError, CertificateError) as e:\n",
      "            # Discard the connection for these exceptions. It will be\n",
      "            # replaced during the next _get_conn() call.\n",
      "            clean_exit = False\n",
      "            if isinstance(e, (BaseSSLError, CertificateError)):\n",
      "                e = SSLError(e)\n",
      "            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:\n",
      "                e = ProxyError('Cannot connect to proxy.', e)\n",
      "            elif isinstance(e, (SocketError, HTTPException)):\n",
      "                e = ProtocolError('Connection aborted.', e)\n",
      "    \n",
      "            retries = retries.increment(method, url, error=e, _pool=self,\n",
      ">                                       _stacktrace=sys.exc_info()[2])\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:639: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n",
      "method = 'GET', url = '/repos/pulls?page=1&state=closed', response = None\n",
      "error = NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',)\n",
      "_pool = <urllib3.connectionpool.HTTPSConnectionPool object at 0x00000264B41DA1D0>\n",
      "_stacktrace = <traceback object at 0x00000264B4147648>\n",
      "\n",
      "    def increment(self, method=None, url=None, response=None, error=None,\n",
      "                  _pool=None, _stacktrace=None):\n",
      "        \"\"\" Return a new Retry object with incremented retry counters.\n",
      "    \n",
      "            :param response: A response object, or None, if the server did not\n",
      "                return a response.\n",
      "            :type response: :class:`~urllib3.response.HTTPResponse`\n",
      "            :param Exception error: An error encountered during the request, or\n",
      "                None if the response was received successfully.\n",
      "    \n",
      "            :return: A new ``Retry`` object.\n",
      "            \"\"\"\n",
      "        if self.total is False and error:\n",
      "            # Disabled, indicate to re-raise the error.\n",
      "            raise six.reraise(type(error), error, _stacktrace)\n",
      "    \n",
      "        total = self.total\n",
      "        if total is not None:\n",
      "            total -= 1\n",
      "    \n",
      "        connect = self.connect\n",
      "        read = self.read\n",
      "        redirect = self.redirect\n",
      "        status_count = self.status\n",
      "        cause = 'unknown'\n",
      "        status = None\n",
      "        redirect_location = None\n",
      "    \n",
      "        if error and self._is_connection_error(error):\n",
      "            # Connect retry?\n",
      "            if connect is False:\n",
      "                raise six.reraise(type(error), error, _stacktrace)\n",
      "            elif connect is not None:\n",
      "                connect -= 1\n",
      "    \n",
      "        elif error and self._is_read_error(error):\n",
      "            # Read retry?\n",
      "            if read is False or not self._is_method_retryable(method):\n",
      "                raise six.reraise(type(error), error, _stacktrace)\n",
      "            elif read is not None:\n",
      "                read -= 1\n",
      "    \n",
      "        elif response and response.get_redirect_location():\n",
      "            # Redirect retry?\n",
      "            if redirect is not None:\n",
      "                redirect -= 1\n",
      "            cause = 'too many redirects'\n",
      "            redirect_location = response.get_redirect_location()\n",
      "            status = response.status\n",
      "    \n",
      "        else:\n",
      "            # Incrementing because of a server error like a 500 in\n",
      "            # status_forcelist and a the given method is in the whitelist\n",
      "            cause = ResponseError.GENERIC_ERROR\n",
      "            if response and response.status:\n",
      "                if status_count is not None:\n",
      "                    status_count -= 1\n",
      "                cause = ResponseError.SPECIFIC_ERROR.format(\n",
      "                    status_code=response.status)\n",
      "                status = response.status\n",
      "    \n",
      "        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)\n",
      "    \n",
      "        new_retry = self.new(\n",
      "            total=total,\n",
      "            connect=connect, read=read, redirect=redirect, status=status_count,\n",
      "            history=history)\n",
      "    \n",
      "        if new_retry.is_exhausted():\n",
      ">           raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "E           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/pulls?page=1&state=closed (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py:388: MaxRetryError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "    def test_jupyterlab():\n",
      ">       assert len(pandas.concat(list(pulls('jupyterlab/jupyterlab'))))\n",
      "\n",
      "pulls.ipynb:73: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "pulls.ipynb:60: in pulls\n",
      "    result = events(project, 'pulls', state=state, page=i)\n",
      "pulls.ipynb:42: in <lambda>\n",
      "    info(x, **params).loc[f'{action}_url'].format(**{'/number': ''})).json())\n",
      "pulls.ipynb:31: in <lambda>\n",
      "    info = lambda x, **params: pandas.Series(requests.get(\"https://api.github.com/repos/{}\".format(x), params=params).json())\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests\\api.py:72: in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests\\api.py:58: in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests_cache\\core.py:126: in request\n",
      "    **kwargs\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:508: in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests_cache\\core.py:99: in send\n",
      "    return send_request_and_cache_response()\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests_cache\\core.py:91: in send_request_and_cache_response\n",
      "    response = super(CachedSession, self).send(request, **kwargs)\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:618: in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <requests.adapters.HTTPAdapter object at 0x00000264B41FAFD0>\n",
      "request = <PreparedRequest [GET]>, stream = False\n",
      "timeout = <urllib3.util.timeout.Timeout object at 0x00000264B41DA208>\n",
      "verify = True, cert = None, proxies = OrderedDict()\n",
      "\n",
      "    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n",
      "        \"\"\"Sends PreparedRequest object. Returns Response object.\n",
      "    \n",
      "            :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n",
      "            :param stream: (optional) Whether to stream the request content.\n",
      "            :param timeout: (optional) How long to wait for the server to send\n",
      "                data before giving up, as a float, or a :ref:`(connect timeout,\n",
      "                read timeout) <timeouts>` tuple.\n",
      "            :type timeout: float or tuple or urllib3 Timeout object\n",
      "            :param verify: (optional) Either a boolean, in which case it controls whether\n",
      "                we verify the server's TLS certificate, or a string, in which case it\n",
      "                must be a path to a CA bundle to use\n",
      "            :param cert: (optional) Any user-provided SSL certificate to be trusted.\n",
      "            :param proxies: (optional) The proxies dictionary to apply to the request.\n",
      "            :rtype: requests.Response\n",
      "            \"\"\"\n",
      "    \n",
      "        conn = self.get_connection(request.url, proxies)\n",
      "    \n",
      "        self.cert_verify(conn, request.url, verify, cert)\n",
      "        url = self.request_url(request, proxies)\n",
      "        self.add_headers(request)\n",
      "    \n",
      "        chunked = not (request.body is None or 'Content-Length' in request.headers)\n",
      "    \n",
      "        if isinstance(timeout, tuple):\n",
      "            try:\n",
      "                connect, read = timeout\n",
      "                timeout = TimeoutSauce(connect=connect, read=read)\n",
      "            except ValueError as e:\n",
      "                # this may raise a string formatting error.\n",
      "                err = (\"Invalid timeout {0}. Pass a (connect, read) \"\n",
      "                       \"timeout tuple, or a single float to set \"\n",
      "                       \"both timeouts to the same value\".format(timeout))\n",
      "                raise ValueError(err)\n",
      "        elif isinstance(timeout, TimeoutSauce):\n",
      "            pass\n",
      "        else:\n",
      "            timeout = TimeoutSauce(connect=timeout, read=timeout)\n",
      "    \n",
      "        try:\n",
      "            if not chunked:\n",
      "                resp = conn.urlopen(\n",
      "                    method=request.method,\n",
      "                    url=url,\n",
      "                    body=request.body,\n",
      "                    headers=request.headers,\n",
      "                    redirect=False,\n",
      "                    assert_same_host=False,\n",
      "                    preload_content=False,\n",
      "                    decode_content=False,\n",
      "                    retries=self.max_retries,\n",
      "                    timeout=timeout\n",
      "                )\n",
      "    \n",
      "            # Send the request.\n",
      "            else:\n",
      "                if hasattr(conn, 'proxy_pool'):\n",
      "                    conn = conn.proxy_pool\n",
      "    \n",
      "                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n",
      "    \n",
      "                try:\n",
      "                    low_conn.putrequest(request.method,\n",
      "                                        url,\n",
      "                                        skip_accept_encoding=True)\n",
      "    \n",
      "                    for header, value in request.headers.items():\n",
      "                        low_conn.putheader(header, value)\n",
      "    \n",
      "                    low_conn.endheaders()\n",
      "    \n",
      "                    for i in request.body:\n",
      "                        low_conn.send(hex(len(i))[2:].encode('utf-8'))\n",
      "                        low_conn.send(b'\\r\\n')\n",
      "                        low_conn.send(i)\n",
      "                        low_conn.send(b'\\r\\n')\n",
      "                    low_conn.send(b'0\\r\\n\\r\\n')\n",
      "    \n",
      "                    # Receive the response from the server\n",
      "                    try:\n",
      "                        # For Python 2.7+ versions, use buffering of HTTP\n",
      "                        # responses\n",
      "                        r = low_conn.getresponse(buffering=True)\n",
      "                    except TypeError:\n",
      "                        # For compatibility with Python 2.6 versions and back\n",
      "                        r = low_conn.getresponse()\n",
      "    \n",
      "                    resp = HTTPResponse.from_httplib(\n",
      "                        r,\n",
      "                        pool=conn,\n",
      "                        connection=low_conn,\n",
      "                        preload_content=False,\n",
      "                        decode_content=False\n",
      "                    )\n",
      "                except:\n",
      "                    # If we hit any problems here, clean up the connection.\n",
      "                    # Then, reraise so that we can handle the actual exception.\n",
      "                    low_conn.close()\n",
      "                    raise\n",
      "    \n",
      "        except (ProtocolError, socket.error) as err:\n",
      "            raise ConnectionError(err, request=request)\n",
      "    \n",
      "        except MaxRetryError as e:\n",
      "            if isinstance(e.reason, ConnectTimeoutError):\n",
      "                # TODO: Remove this in 3.0.0: see #2811\n",
      "                if not isinstance(e.reason, NewConnectionError):\n",
      "                    raise ConnectTimeout(e, request=request)\n",
      "    \n",
      "            if isinstance(e.reason, ResponseError):\n",
      "                raise RetryError(e, request=request)\n",
      "    \n",
      "            if isinstance(e.reason, _ProxyError):\n",
      "                raise ProxyError(e, request=request)\n",
      "    \n",
      "            if isinstance(e.reason, _SSLError):\n",
      "                # This branch is for urllib3 v1.22 and later.\n",
      "                raise SSLError(e, request=request)\n",
      "    \n",
      ">           raise ConnectionError(e, request=request)\n",
      "E           requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/pulls?page=1&state=closed (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000264B34C9CC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:508: ConnectionError\n",
      "========================== 1 failed in 18.69 seconds ==========================\n",
      "---------------------------------------------------------------------------\n",
      "SystemExit                                Traceback (most recent call last)\n",
      "C:\\Anaconda3\\lib\\runpy.py in run_module(mod_name, init_globals, run_name, alter_sys)\n",
      "    203         run_name = mod_name\n",
      "    204     if alter_sys:\n",
      "--> 205         return _run_module_code(code, init_globals, run_name, mod_spec)\n",
      "    206     else:\n",
      "    207         # Leave the sys module alone\n",
      "\n",
      "C:\\Anaconda3\\lib\\runpy.py in _run_module_code(code, init_globals, mod_name, mod_spec, pkg_name, script_name)\n",
      "     94         mod_globals = temp_module.module.__dict__\n",
      "     95         _run_code(code, mod_globals, init_globals,\n",
      "---> 96                   mod_name, mod_spec, pkg_name, script_name)\n",
      "     97     # Copy the globals of the temporary module, as they\n",
      "     98     # may be cleared when the temporary module goes away\n",
      "\n",
      "C:\\Anaconda3\\lib\\runpy.py in _run_code(code, run_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\n",
      "     83                        __package__ = pkg_name,\n",
      "     84                        __spec__ = mod_spec)\n",
      "---> 85     exec(code, run_globals)\n",
      "     86     return run_globals\n",
      "     87 \n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\pytest.py in <module>()\n",
      "     72     # we trigger the below \"else\" condition by the following import\n",
      "     73     import pytest\n",
      "---> 74     raise SystemExit(pytest.main())\n",
      "     75 else:\n",
      "     76 \n",
      "\n",
      "SystemExit: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2634: UserWarning: Unknown failure executing module: <pytest>\n",
      "  warn('Unknown failure executing module: <%s>' % mod_name)\n"
     ]
    }
   ],
   "source": [
    "    if __name__ == '__main__':\n",
    "        !ipython -m pytest -- pulls.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
